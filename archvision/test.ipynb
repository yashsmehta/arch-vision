{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ccb4f57-8a9b-4cc4-9fb4-2c418cc64423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559e55f-3bf2-4fd4-9202-f0c574021662",
   "metadata": {},
   "source": [
    "## load custom alexnet and select layer to extract activations from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7442c0-0f56-4b4f-956d-f4fb3b880201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.get_layers of Model(\n",
      "  (base_model): AlexNet(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.5, inplace=False)\n",
      "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (last): Last()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "from models.alexnet import AlexNet\n",
    "alexnet_model = AlexNet(layer_name='features.12').build()\n",
    "\n",
    "print(alexnet_model.get_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d4136-0340-4c7d-a129-b2a4719552c2",
   "metadata": {},
   "source": [
    "## load train images from tiny imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d72b466-f91f-4d09-b145-0d0ba1ba3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_image_paths(train_dir):\n",
    "    \"\"\" Retrieve all image paths from the training directory of Tiny ImageNet. \"\"\"\n",
    "    image_paths = []\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        class_path = os.path.join(train_dir, class_dir)\n",
    "        images_path = os.path.join(class_path, 'images')\n",
    "        \n",
    "        if os.path.isdir(images_path):\n",
    "            for image_file in os.listdir(images_path):\n",
    "                image_path = os.path.join(images_path, image_file)\n",
    "                if os.path.isfile(image_path):\n",
    "                    image_paths.append(image_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Usage\n",
    "train_dir = '/data/atlas/datasets/tiny-imagenet-200/train'\n",
    "image_paths = get_train_image_paths(train_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468077e-baed-44cd-b040-87666b5b5c6f",
   "metadata": {},
   "source": [
    "## define preprocess func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "210aca82-8e15-4aad-8eed-6b5702140907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "# Define your transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb47bf-ec8d-4df9-93d6-37a264bb9bf1",
   "metadata": {},
   "source": [
    "## load and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2baf7b6-c34a-4b7e-a6ca-b2efd3982c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform_images(image_paths, preprocess):\n",
    "    \"\"\" Load images from paths and apply the specified torchvision transform. \"\"\"\n",
    "    return torch.stack([preprocess(Image.open(image_path).convert('RGB')) for image_path in image_paths])\n",
    "\n",
    "\n",
    "processed_images = load_and_transform_images(image_paths, preprocess)\n",
    "print(processed_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b069e-6ae3-43fc-854e-1b67975da57e",
   "metadata": {},
   "source": [
    "## extract activations from alexnet for tiny imagenet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc39d7f5-84e5-4b44-9656-e3dc2b0e83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = alexnet_model(processed_images)\n",
    "print(activations.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
